{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YquGSYME_B5z"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oz3uzog5wwQM"
   },
   "source": [
    "# Importing of Packages and Defining Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PVjqeNPowwQN"
   },
   "source": [
    "## Import packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vl-HKeJJwwQP"
   },
   "outputs": [],
   "source": [
    "# Normal packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "%matplotlib inline\n",
    "\n",
    "# Statsmodels\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "# Counter\n",
    "from collections import Counter\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import Session, sessionmaker\n",
    "from sqlalchemy import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "s6AsUbfMwwQU"
   },
   "source": [
    "## Define Functions (from proj 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "O0xNoo6vwwQV"
   },
   "source": [
    "### def check_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "UEz2Osm_wwQW"
   },
   "outputs": [],
   "source": [
    "# Check columns returns the datatype, null values and unique values of input series \n",
    "def check_column(series,nlargest='all'):\n",
    "    print(f\"Column: df['{series.name}']':\")\n",
    "    print(f\"dtype: {series.dtype}\")\n",
    "    print(f\"isna: {series.isna().sum()} out of {len(series)} - {round(series.isna().sum()/len(series)*100,3)}%\")\n",
    "        \n",
    "    print(f'\\nUnique non-na values:') #,df['waterfront'].unique())\n",
    "    if nlargest =='all':\n",
    "        print(series.value_counts())\n",
    "    else:\n",
    "        print(series.value_counts().nlargest(nlargest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "GtI-okJkwwQa"
   },
   "source": [
    "### def multiplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "i7lFBscHwwQb"
   },
   "outputs": [],
   "source": [
    "# MULTIPLOT\n",
    "from string import ascii_letters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def multiplot(df):\n",
    "    \"\"\"Plots results from df.corr() in a correlation heat map for multicollinearity.\n",
    "    Returns fig, ax objects\"\"\"\n",
    "    sns.set(style=\"white\")\n",
    "\n",
    "    # Compute the correlation matrix\n",
    "    corr = df.corr()\n",
    "\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(16, 16))\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(corr, mask=mask, annot=True, cmap=cmap, center=0,\n",
    "                \n",
    "    square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "    return f, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "Qk9N1jMywwQf"
   },
   "source": [
    "### def detect_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "LzpDuDd5wwQg"
   },
   "outputs": [],
   "source": [
    "# Tukey's method using IQR to eliminate \n",
    "def detect_outliers(df, n, features):\n",
    "    \"\"\"Uses Tukey's method to return outer of interquartile ranges to return indices if outliers in a dataframe.\n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrane containing columns of features\n",
    "    n: default is 0, multiple outlier cutoff  \n",
    "    \n",
    "    Returns:\n",
    "    Index of outliers for .loc\n",
    "    \n",
    "    Examples:\n",
    "    Outliers_to_drop = detect_outliers(data,2,[\"col1\",\"col2\"]) Returning value\n",
    "    df.loc[Outliers_to_drop] # Show the outliers rows\n",
    "    data= data.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)\n",
    "   \"\"\"\n",
    "\n",
    "# Drop outliers    \n",
    "\n",
    "    outlier_indices = []\n",
    "    # iterate over features(columns)\n",
    "    for col in features:\n",
    "        \n",
    "        # 1st quartile (25%)\n",
    "        Q1 = np.percentile(df[col], 25)\n",
    "        # 3rd quartile (75%)\n",
    "        Q3 = np.percentile(df[col],75)\n",
    "        \n",
    "        # Interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        # outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "        \n",
    "        # Determine a list of indices of outliers for feature col\n",
    "        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n",
    "        \n",
    "        # append the found outlier indices for col to the list of outlier indices \n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "        \n",
    "        # select observations containing more than 2 outliers\n",
    "        outlier_indices = Counter(outlier_indices)        \n",
    "        multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n",
    "    return multiple_outliers \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OQRJsISzg38q"
   },
   "source": [
    "###def plot_wide_kde_thin_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h7VFkvV6g0Gv"
   },
   "outputs": [],
   "source": [
    "def plot_wide_kde_thin_bar(series1,sname1, series2, sname2):\n",
    "    '''Plot series1 and series 2 on wide kde plot with small mean+sem bar plot.'''\n",
    "    \n",
    "    ## ADDING add_gridspec usage\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from scipy.stats import sem\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.ticker as ticker\n",
    "    %matplotlib inline\n",
    "\n",
    "    import seaborn as sns\n",
    "\n",
    "    from matplotlib import rcParams\n",
    "    from matplotlib import rc\n",
    "    rcParams['font.family'] = 'serif'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Plot distributions of discounted vs full price groups\n",
    "    plt.style.use('default')\n",
    "    # with plt.style.context(('tableau-colorblind10')):\n",
    "    with plt.style.context(('seaborn-notebook')):\n",
    "\n",
    "        \n",
    "\n",
    "        ## ----------- DEFINE AESTHETIC CUSTOMIZATIONS ----------- ##\n",
    "       # Axis Label fonts\n",
    "        fontSuptitle ={'fontsize': 22,\n",
    "                   'fontweight': 'bold',\n",
    "                    'fontfamily':'serif'}\n",
    "\n",
    "        fontTitle = {'fontsize': 10,\n",
    "                   'fontweight': 'medium',\n",
    "                    'fontfamily':'serif'}\n",
    "\n",
    "        fontAxis = {'fontsize': 10,\n",
    "                   'fontweight': 'medium',\n",
    "                    'fontfamily':'serif'}\n",
    "\n",
    "        fontTicks = {'fontsize': 8,\n",
    "                   'fontweight':'medium', \n",
    "                    'fontfamily':'serif'}\n",
    "\n",
    "\n",
    "        ## --------- CREATE FIG BASED ON GRIDSPEC --------- ##\n",
    "        \n",
    "        plt.suptitle('Quantity of Units Sold', fontdict = fontSuptitle)\n",
    "\n",
    "        # Create fig object and declare figsize\n",
    "        fig = plt.figure(constrained_layout=True, figsize=(8,3))\n",
    "        \n",
    "        # Define gridspec to create grid coordinates             \n",
    "        gs = fig.add_gridspec(nrows=2,ncols=20)\n",
    "\n",
    "        # Assign grid space to ax with add_subplot\n",
    "        ax0 = fig.add_subplot(gs[:,0:16])\n",
    "        ax1 = fig.add_subplot(gs[:,16:])\n",
    "        \n",
    "        #Combine into 1 list\n",
    "        ax = [ax0,ax1]\n",
    "        \n",
    "        ## --------- DEFINE SUBPLOT GROUPS DATA, LABELS, AND STYLE --------- ##\n",
    "        \n",
    "        \n",
    "        ax[0].set_title('Histogram + KDE',fontdict=fontTitle)\n",
    "\n",
    "        # Group 1: data, label, hist_kws and kde_kws\n",
    "        plotS1 = {'data': series1, 'label': sname1.title(),\n",
    "\n",
    "                   'hist_kws' :\n",
    "                    {'edgecolor': 'black', 'color':'darkgray','alpha': 0.8, 'lw':0.5},\n",
    "\n",
    "                   'kde_kws':\n",
    "                    {'color':'gray', 'linestyle': '--', 'linewidth':2,\n",
    "                     'label':'kde'}}\n",
    "\n",
    "        # Group 2: data, label, hist_kws and kde_kws\n",
    "        plotS2 = {'data': series2,\n",
    "                    'label': sname2.title(), \n",
    "\n",
    "                    'hist_kws' :\n",
    "                    {'edgecolor': 'black','color':'green','alpha':0.8 ,'lw':0.5},\n",
    "\n",
    "\n",
    "                    'kde_kws':\n",
    "                    {'color':'darkgreen','linestyle':':','linewidth':3,'label':'kde'}}\n",
    "        \n",
    "        # plot group 1\n",
    "        sns.distplot(plotS1['data'], label=plotS1['label'],\n",
    "                   \n",
    "                     hist_kws = plotS1['hist_kws'], kde_kws = plotS1['kde_kws'],\n",
    "                     \n",
    "                     ax=ax[0])   \n",
    "      \n",
    "\n",
    "        # plot group 2\n",
    "        sns.distplot(plotS2['data'], label=plotS2['label'],\n",
    "                     \n",
    "                     hist_kws=plotS2['hist_kws'], kde_kws = plotS2['kde_kws'],\n",
    "                     \n",
    "                     ax=ax[0])\n",
    "\n",
    "\n",
    "        ax[0].set_xlabel(series1.name, fontdict=fontAxis)\n",
    "        ax[0].set_ylabel('Kernel Density Estimation',fontdict=fontAxis)\n",
    "\n",
    "        ax[0].tick_params(axis='both',labelsize=fontTicks['fontsize'])   \n",
    "        ax[0].legend()\n",
    "\n",
    "\n",
    "        # SUBPLOT 2 \n",
    "        # Import scipy for error bars\n",
    "        from scipy import stats\n",
    "\n",
    "        x = [plotS1['label'], plotS2['label']]\n",
    "        y = [np.mean(plotS1['data']),np.mean(plotS2['data'])]\n",
    "\n",
    "        yerr = [stats.sem(plotS1['data']),  stats.sem(plotS2['data'])]\n",
    "        err_kws = {'ecolor':'black','capsize':10,'capthick':1,'elinewidth':1}\n",
    "\n",
    "        ax[1].bar(x,y,align='center', edgecolor='black', yerr=yerr,error_kw=err_kws,width=0.6)\n",
    "\n",
    "        # Customize subplot 2\n",
    "        ax[1].set_title('Average Quantities Sold',fontdict=fontTitle)\n",
    "#         ax[1].set_xlabel('Sales Price', fontdict=fontAxis)\n",
    "        ax[1].set_ylabel('Mean +/- SEM ',fontdict=fontAxis)\n",
    "        ax[1].tick_params(axis=y,labelsize=fontTicks['fontsize'])\n",
    "\n",
    "        ax[1].tick_params(axis=x,labelsize=fontTicks['fontsize'],rotation=45)\n",
    "#         fig.savefig('H1_EDA_using_gridspec.png')\n",
    "        plt.tight_layout()\n",
    "    #     print(f')\n",
    "\n",
    "        plt.show()\n",
    "        return fig,ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xPRvkOxkhBfq"
   },
   "source": [
    "###def plot_hist_scat_sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "MITbzaCcwwQl"
   },
   "outputs": [],
   "source": [
    "# Plots histogram and scatter (vs price) side by side\n",
    "def plot_hist_scat_sns(df, target='index'):\n",
    "    \"\"\"Plots seaborne distplots and regplots for columns im datamframe vs target.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame.describe() columns will be used. \n",
    "    target = name of column containing target variable.assume first coluumn. \n",
    "    \n",
    "    Returns:\n",
    "    Figures for each column vs target with 2 subplots.\n",
    "   \"\"\"\n",
    "    import matplotlib.ticker as mtick\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    with plt.style.context(('seaborn-paper')):\n",
    "        ###  DEFINE AESTHETIC CUSTOMIZATIONS  -------------------------------##\n",
    "\n",
    "\n",
    "        plt.style.use('dark_background')\n",
    "        figsize=(10,8)\n",
    "\n",
    "        # Axis Label fonts\n",
    "        fontTitle = {'fontsize': 12,\n",
    "                   'fontweight': 'bold',\n",
    "                    'fontfamily':'serif'}\n",
    "\n",
    "        fontAxis = {'fontsize': 10,\n",
    "                   'fontweight': 'bold',\n",
    "                    'fontfamily':'serif'}\n",
    "\n",
    "        fontTicks = {'fontsize': 8,\n",
    "                   'fontweight':'bold',\n",
    "                    'fontfamily':'serif'}\n",
    "\n",
    "        # Formatting dollar sign labels\n",
    "        fmtPrice = '${x:,.0f}'\n",
    "        tickPrice = mtick.StrMethodFormatter(fmtPrice)\n",
    "\n",
    "\n",
    "        ###  PLOTTING ----------------------------- ------------------------ ##\n",
    "\n",
    "        # Loop through dataframe to plot\n",
    "        for column in df.describe():\n",
    "\n",
    "            # Create figure with subplots for current column\n",
    "            fig, ax = plt.subplots(figsize=figsize, ncols=2, nrows=2)\n",
    "\n",
    "            ##  SUBPLOT 1 --------------------------------------------------##\n",
    "            i,j = 0,0\n",
    "            ax[i,j].set_title(column.capitalize(),fontdict=fontTitle)\n",
    "\n",
    "            # Define graphing keyword dictionaries for distplot (Subplot 1)\n",
    "            hist_kws = {\"linewidth\": 1, \"alpha\": 1, \"color\": 'blue','edgecolor':'w'}\n",
    "            kde_kws = {\"color\": \"white\", \"linewidth\": 1, \"label\": \"KDE\"}\n",
    "\n",
    "            # Plot distplot on ax[i,j] using hist_kws and kde_kws\n",
    "            sns.distplot(df[column], norm_hist=True, kde=True,\n",
    "                         hist_kws = hist_kws, kde_kws = kde_kws,\n",
    "                         label=column+' histogram', ax=ax[i,j])\n",
    "\n",
    "\n",
    "            # Set x axis label\n",
    "            ax[i,j].set_xlabel(column.title(),fontdict=fontAxis)\n",
    "\n",
    "            # Get x-ticks, rotate labels, and return\n",
    "            xticklab1 = ax[i,j].get_xticklabels(which = 'both')\n",
    "            ax[i,j].set_xticklabels(labels=xticklab1, fontdict=fontTicks, rotation=45)\n",
    "            ax[i,j].xaxis.set_major_formatter(mtick.ScalarFormatter())\n",
    "\n",
    "\n",
    "            # Set y-label \n",
    "            ax[i,j].set_ylabel('Density',fontdict=fontAxis)\n",
    "            yticklab1=ax[i,j].get_yticklabels(which='both')\n",
    "            ax[i,j].set_yticklabels(labels=yticklab1,fontdict=fontTicks)\n",
    "            ax[i,j].yaxis.set_major_formatter(mtick.ScalarFormatter())\n",
    "\n",
    "\n",
    "            # Set y-grid\n",
    "            ax[i, j].set_axisbelow(True)\n",
    "            ax[i, j].grid(axis='y',ls='--')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            ##  SUBPLOT 2-------------------------------------------------- ##\n",
    "            i,j = 0,1\n",
    "            ax[i,j].set_title(column.capitalize(),fontdict=fontTitle)\n",
    "\n",
    "            # Define the kwd dictionaries for scatter and regression line (subplot 2)\n",
    "            line_kws={\"color\":\"white\",\"alpha\":0.5,\"lw\":4,\"ls\":\":\"}\n",
    "            scatter_kws={'s': 2, 'alpha': 0.5,'marker':'.','color':'blue'}\n",
    "\n",
    "            # Plot regplot on ax[i,j] using line_kws and scatter_kws\n",
    "            sns.regplot(df[column], df[target], \n",
    "                        line_kws = line_kws,\n",
    "                        scatter_kws = scatter_kws,\n",
    "                        ax=ax[i,j])\n",
    "\n",
    "            # Set x-axis label\n",
    "            ax[i,j].set_xlabel(column.title(),fontdict=fontAxis)\n",
    "\n",
    "             # Get x ticks, rotate labels, and return\n",
    "            xticklab2=ax[i,j].get_xticklabels(which='both')\n",
    "            ax[i,j].set_xticklabels(labels=xticklab2,fontdict=fontTicks, rotation=45)\n",
    "            ax[i,j].xaxis.set_major_formatter(mtick.ScalarFormatter())\n",
    "\n",
    "            # Set  y-axis label\n",
    "            ax[i,j].set_ylabel(target,fontdict=fontAxis)\n",
    "\n",
    "            # Get, set, and format y-axis Price labels\n",
    "            yticklab = ax[i,j].get_yticklabels()\n",
    "            ax[i,j].set_yticklabels(yticklab,fontdict=fontTicks)\n",
    "            ax[i,j].yaxis.set_major_formatter(mtick.ScalarFormatter())\n",
    "\n",
    "    #         ax[i,j].get_yaxis().set_major_formatter(tickPrice) \n",
    "\n",
    "            # Set y-grid\n",
    "            ax[i, j].set_axisbelow(True)\n",
    "            ax[i, j].grid(axis='y',ls='--')       \n",
    "\n",
    "            ## ---------- Final layout adjustments ----------- ##\n",
    "            # Deleted unused subplots \n",
    "            fig.delaxes(ax[1,1])\n",
    "            fig.delaxes(ax[1,0])\n",
    "\n",
    "            # Optimizing spatial layout\n",
    "            fig.tight_layout()\n",
    "            figtitle=column+'_dist_regr_plots.png'\n",
    "            plt.savefig(figtitle)\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BVwy49ADwwQn"
   },
   "source": [
    "## Defining Functions (Proj 2 specific)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nkPB_HcdwwQo"
   },
   "source": [
    "### def list2df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TwdV-j85wwQp"
   },
   "outputs": [],
   "source": [
    "def list2df(list):#, sort_values='index'):\n",
    "    \"\"\" Take in a list where row[0] = column_names and outputs a dataframe.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    set_index -- df.set_index(set_index)\n",
    "    sortby -- df.sorted()\n",
    "    \"\"\"    \n",
    "    \n",
    "    df_list = pd.DataFrame(list[1:],columns=list[0])\n",
    "#     df_list = df_list[1:]\n",
    "\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ekTOehxHwwQu"
   },
   "source": [
    "### def get_col_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LOaNcafFwwQv"
   },
   "outputs": [],
   "source": [
    "def  get_col_info(col_name):\n",
    "    \"\"\"Gets the column names and data types from the alchamey inspector object.\n",
    "    Returns column_info dataframe of table details.\n",
    "    \"\"\"\n",
    "    col_list = inspector.get_columns(col_name)\n",
    "    \n",
    "    column_info = [['table','column','dtype']]\n",
    "    print(f'Table Name: {col_name}\\n')\n",
    "\n",
    "    for col in col_list:\n",
    "        column_info.append([str(col_name),col['name'], col['type']])\n",
    "        \n",
    "    df = list2df(column_info)\n",
    "    return column_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O7Xq2RqAR0va"
   },
   "source": [
    "### def describe_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ne6vEM4CwwQ3"
   },
   "outputs": [],
   "source": [
    "# describe_outliers -- calls detect_outliers\n",
    "def describe_outliers(df):\n",
    "    \"\"\" Returns a new_df of outliers, and % outliers each col using detect_outliers.\n",
    "    \"\"\"\n",
    "    out_count = 0\n",
    "    new_df = pd.DataFrame(columns=['total_outliers', 'percent_total'])\n",
    "    for col in df.columns:\n",
    "        outies = detect_outliers(df[col])\n",
    "        out_count += len(outies) \n",
    "        new_df.loc[col] = [len(outies), round((len(outies)/len(df.index))*100, 2)]\n",
    "    new_df.loc['grand_total'] = [sum(new_df['total_outliers']), sum(new_df['percent_total'])]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XrvSuzkKwwQz"
   },
   "source": [
    "### def get_full_table_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A0bruXiLwwQ0"
   },
   "outputs": [],
   "source": [
    "def  get_full_table_info(engine):\n",
    "    \"\"\"Gets the table names, their column namesand data types engine.\n",
    "    Returns column_info dataframe of table details.\n",
    "    \"\"\"\n",
    "    column_info = [['table','column','dtype']]\n",
    "    \n",
    "    list_tables= engine.table_names()\n",
    "    \n",
    "    for table in list_tables:\n",
    "        \n",
    "        col_list = inspector.get_columns(table)\n",
    "        \n",
    "        for col in col_list:\n",
    "            \n",
    "            column_info.append([str(table),col['name'], col['type'],col['']])\n",
    "            inspector.get_foreign_keys()\n",
    "    \n",
    "    df = list2df(column_info)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EDLKQNdKR4Cb"
   },
   "source": [
    "### def Cohen's d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F_vkRMKMRO0Z"
   },
   "outputs": [],
   "source": [
    "#### Cohen's d\n",
    "def Cohen_d(group1, group2):\n",
    "    # Compute Cohen's d.\n",
    "    # group1: Series or NumPy array\n",
    "    # group2: Series or NumPy array\n",
    "    # returns a floating point number \n",
    "    diff = group1.mean() - group2.mean()\n",
    "\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    var1 = group1.var()\n",
    "    var2 = group2.var()\n",
    "\n",
    "    # Calculate the pooled threshold as shown earlier\n",
    "    pooled_var = (n1 * var1 + n2 * var2) / (n1 + n2)\n",
    "    \n",
    "    # Calculate Cohen's d statistic\n",
    "    d = diff / np.sqrt(pooled_var)\n",
    "    \n",
    "    return d\n",
    "\n",
    "\n",
    "def plot_pdfs(cohen_d=2):\n",
    "    \"\"\"Plot PDFs for distributions that differ by some number of stds.\n",
    "    \n",
    "    cohen_d: number of standard deviations between the means\n",
    "    \"\"\"\n",
    "    group1 = scipy.stats.norm(0, 1)\n",
    "    group2 = scipy.stats.norm(cohen_d, 1)\n",
    "    xs, ys = evaluate_PDF(group1)\n",
    "    pyplot.fill_between(xs, ys, label='Group1', color='#ff2289', alpha=0.7)\n",
    "\n",
    "    xs, ys = evaluate_PDF(group2)\n",
    "    pyplot.fill_between(xs, ys, label='Group2', color='#376cb0', alpha=0.7)\n",
    "    \n",
    "    o, s = overlap_superiority(group1, group2)\n",
    "    print('overlap', o)\n",
    "    print('superiority', s)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W6qgv8Pl_1Hu"
   },
   "source": [
    "### def normtest_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_bc2zw82_c8F"
   },
   "outputs": [],
   "source": [
    "def normtest_results(dict_data):\n",
    "    \"\"\"Peforms both d'agostino-pearson and shapiro-wilik normal tests\n",
    "        \n",
    "        Parameters:\n",
    "            dict_data -- dictionary with {'name' : data} \n",
    "        Returns:\n",
    "            results_normtest -- list of test results (can run list2df(results_normtest)\n",
    "    \"\"\"\n",
    "    from numpy.random import seed\n",
    "    from numpy.random import randn\n",
    "    from scipy.stats import shapiro\n",
    "    from scipy.stats import normaltest\n",
    "\n",
    "    results_normtest_shap = [['DataIn','Test','stat','p']]\n",
    "    results_normtest_dagp = [['DataIn','Test','stat','p']]\n",
    "\n",
    "    for key,val in dict_data.items():\n",
    "\n",
    "        data_in = val\n",
    "        name = key\n",
    "        test = 'Shapiro'\n",
    "        stat, p = shapiro(data_in)\n",
    "        results_normtest_shap.append([name , test, stat , p ])\n",
    "        test = 'D’Agostino’s'\n",
    "        stat, p = normaltest(data_in)\n",
    "        results_normtest_dagp.append([name,test,stat, p])\n",
    "\n",
    "    results_normtest = pd.concat([list2df(results_normtest_shap), list2df(results_normtest_dagp)]) \n",
    "\n",
    "    return results_normtest #, list2df(results_normtest_shap),list2df(results_normtest_dagp)\n",
    "\n",
    "#   results_pivot = results.pivot(index='DataIn', columns= 'Test')\n",
    "#   results_pivot.stack(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iOxElICo_34g"
   },
   "source": [
    "### def quant_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zIcRSLF__ret"
   },
   "outputs": [],
   "source": [
    "# TRANSFORM DATA BEFORE RE-CALLING ORIGINAL normtest_results\n",
    "def quant_transform(data_in):\n",
    "    '''Use sklearn.preprocessing.QuantileTransformer to remove outliers from dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        data_in (dict) -- dictionary with data series as values to be processed.\n",
    "    Returns: \n",
    "        data_tf (dict) -- dicionary of same keys from data_in, but transformed.\n",
    "        '''\n",
    "    \n",
    "    from sklearn import preprocessing as prep \n",
    "    from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "    qt =  QuantileTransformer(n_quantiles=10,output_distribution='normal')\n",
    "    data_tf = {}\n",
    "    for k,v in data_in.items():    \n",
    "        data = np.array(v).reshape(-1,1)\n",
    "        transformed = pd.Series(np.squeeze(qt.fit_transform(data)))\n",
    "      \n",
    "        data_tf[k] = transformed\n",
    "    \n",
    "    return data_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dBDZ_d_71Vat"
   },
   "source": [
    "# Hypothesis 3\n",
    "Does the time of year affect quantity of items sold?\n",
    "\n",
    " - H0 = The month of an order has no affect on the mean quantity of items sold.\n",
    "\n",
    " - HA = THe month an order is placed relates to either a higher or lower mean quantity of items sold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7PaYTrUi1YH0"
   },
   "source": [
    "_________\n",
    "## ***Aim 1.1 : To select the proper dataset for analyiss  and generate data groups for testing.***\n",
    "\n",
    "#### Importing Method\n",
    "- Use sqlalchemy to create engine to connect to Northwind_small.sqlite.\n",
    "ENTER YOUR SQL HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24446,
     "status": "ok",
     "timestamp": 1554694282065,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "flNBkgM2RY3-",
    "outputId": "3f684118-a9e6-4108-8f27-42d007a65c3c"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d7135adb1d58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#only colab below\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'/content/drive/My Drive/Colab Notebooks/datasets/Northwind_small.sqlite'\u001b[0m\u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import Session, sessionmaker\n",
    "\n",
    "\n",
    "#only colab below\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/', force_remount=True)\n",
    "filepath = '/content/drive/My Drive/Colab Notebooks/datasets/Northwind_small.sqlite'# \n",
    "#colab above\n",
    "\n",
    "\n",
    "#if running locally\n",
    "#filepath = 'northwind_small.sqlite'\n",
    "\n",
    "engine = create_engine('sqlite:///'+filepath,echo=True)\n",
    "inspector = inspect(engine);\n",
    "\n",
    "# df_employee = pd.read_sql_query(\"SELECT Id, Title, LastName, HireDate , BirthDate  FROM [EMPLOYEE]\", engine )\n",
    "# df_cust_ord = pd.read_sql_query(\"SELECT *FROM [Order] JOIN [Customer] ON [Customer].Id = [Order].CustomerId\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24424,
     "status": "ok",
     "timestamp": 1554694282067,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "HgE9TMkNh3Pu",
    "outputId": "720ab96a-289d-4baa-e2ae-2d4a3d9a0e60"
   },
   "outputs": [],
   "source": [
    "df_ord = pd.read_sql_query(\"SELECT * FROM OrderDetail JOIN [Order]  ON [Order].Id = OrderDetail.OrderId\", engine)\n",
    "# df_ord = pd.concat([df_ord, df_employee['Title']], axis=1)\n",
    "df_ord.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NA8ibZmLiCEC"
   },
   "outputs": [],
   "source": [
    "#Drop wht we dont need\n",
    "df_ord.drop(['OrderId', 'ShipName', 'ShippedDate', 'RequiredDate', 'ShipVia','ShipAddress',\n",
    "             'RequiredDate','ShippedDate', 'ShippedDate', 'ShipCity', 'ShipCountry',\n",
    "            'ShipRegion', 'Freight'],inplace=True, axis=1)\n",
    "\n",
    "\n",
    "# relabel the Id column so they have unique names\n",
    "df_ord.columns = ['Id', 'ProductId', 'UnitPrice', 'Quantity', 'Discount', 'OrderId',\n",
    "       'CustomerId', 'EmployeeId', 'OrderDate', 'ShipPostalCode']\n",
    "\n",
    "# df_ord['OrderDate'] = pd.to_datetime(df_ord.OrderDate )\n",
    "# df_ord.OrderDate.sort_values().min(), df_ord.OrderDate.sort_values().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BZ7haVualclY"
   },
   "source": [
    "### Engineering price features for our hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-qewqDkPectU"
   },
   "source": [
    "##### def calc_product_price & cal_order_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J9YIedhAu-O2"
   },
   "outputs": [],
   "source": [
    "#from James\n",
    "def calc_product_price(row):\n",
    "    price = row['UnitPrice']*(1-row['Discount'])*row['Quantity']\n",
    "    row['price'] = price\n",
    "    if row['Discount']>0:\n",
    "        row['OnSale'] = True\n",
    "    else:\n",
    "        row['OnSale'] = False\n",
    "    return row    \n",
    "\n",
    "# Use calc_order_total to fill in order_total column\n",
    "def calc_order_total(row,df):\n",
    "    order = row['OrderId']\n",
    "    df_temp = df.groupby('OrderId').get_group(order)\n",
    "\n",
    "    \n",
    "    if any(df_temp['OnSale']):\n",
    "        row['discounted_order'] = True\n",
    "    else:\n",
    "        row['discounted_order'] = False\n",
    "    \n",
    "    order_total = df_temp['price'].sum()\n",
    "    row['order_total'] = order_total\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wyb-1bCvd90c"
   },
   "source": [
    "##### make new df with new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34115,
     "status": "ok",
     "timestamp": 1554694291801,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "MfRRthIDeFeQ",
    "outputId": "6e53e828-8a1e-4045-ee1d-99ea687bae57"
   },
   "outputs": [],
   "source": [
    "#Apply calc_product_price to every row \n",
    "\n",
    "df_price = df_ord.apply(lambda x: calc_product_price(x),axis=1)\n",
    "\n",
    "# Apply_calc_order_total to every row\n",
    "\n",
    "df_price = df_price.apply(lambda x: calc_order_total(x,df_price), axis=1)  \n",
    "df_price.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qed8obkqmaX_"
   },
   "source": [
    "#### Adding datetime columns for day of week and month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34090,
     "status": "ok",
     "timestamp": 1554694291802,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "SJ0oHs0agtro",
    "outputId": "e23b11d5-41b1-4430-d66e-e4850ec9d286"
   },
   "outputs": [],
   "source": [
    "#convert dates to datetime\n",
    "df_price['OrderDate'] = pd.to_datetime(df_price.OrderDate )\n",
    "df_price.OrderDate.sort_values().min(), df_price.OrderDate.sort_values().max()# seeing date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K6ISt698TKFB"
   },
   "outputs": [],
   "source": [
    "# concat two dfs\n",
    "# df_price = pd.concat([df_price, df_ord[['OrderDate']]], axis=1) #, 'EmployeeId', 'employee_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34060,
     "status": "ok",
     "timestamp": 1554694291808,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "suMU_rYsTwGA",
    "outputId": "8a750dc8-e0e4-4fc1-d3e1-e3f83ed585f1"
   },
   "outputs": [],
   "source": [
    "# create columns for day of week and month\n",
    "df_price['OrderDate'] = pd.to_datetime(df_price.OrderDate) \n",
    "\n",
    "df_price['week_day'] = df_price['OrderDate'].dt.dayofweek\n",
    "df_price['month'] = df_price['OrderDate'].dt.month\n",
    "\n",
    "df_price.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34034,
     "status": "ok",
     "timestamp": 1554694291809,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "-bLcUQq5TO2-",
    "outputId": "cb2a4b56-8d2e-4173-89cc-63687593edbc"
   },
   "outputs": [],
   "source": [
    "criteria = df_price['month'] <= 6 # boolean selector used to select parts of df for possible plotting options\n",
    "\n",
    "#drop duplicate orders based on OrderId to not inflate or deflate order_total mean\n",
    "# split in two for exploring subsets\n",
    "df_month6 = df_price.loc[criteria,['month','order_total','Discount','OrderId']].drop_duplicates(['OrderId'])\n",
    "df_month12 = df_price.loc[~criteria,['month','order_total','Discount','OrderId']].drop_duplicates(['OrderId'])\n",
    "\n",
    "#Did use this variable\n",
    "total_order = pd.concat([df_month6['order_total'], df_month12['order_total']],axis=0)\n",
    "len(total_order) == len(df_month6['order_total'])+len(df_month12['order_total']) # verifying correct lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "59EIWG2zlOQv"
   },
   "source": [
    "####Subset our final working dataframe for further testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34011,
     "status": "ok",
     "timestamp": 1554694291810,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "W3ISv47sTXEe",
    "outputId": "ca48f106-f457-423d-94c6-ad0b658c2b50"
   },
   "outputs": [],
   "source": [
    "df_year = df_price.loc[:,['month', 'order_total', 'Discount', 'OrderId']].drop_duplicates(['OrderId'])\n",
    "df_year.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d64NuV4ylahh"
   },
   "source": [
    "#### Create a dictionary containing keys and values representing months to assist in plotting and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33988,
     "status": "ok",
     "timestamp": 1554694291811,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "SIQ4qydMlyF-",
    "outputId": "916dc78c-27a8-410b-f353-71533310bf71"
   },
   "outputs": [],
   "source": [
    "#make list of month names (strings)\n",
    "months = ['jan','feb', 'mar', 'apr', 'may' , 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']#creating label names\n",
    "#make corresponding list of integers from 1 = 'jan' through 12 = 'dec'\n",
    "month_code = list(range(1,len(months)+1))\n",
    "month_dict = dict(zip(month_code,months)) # zip the two into a dictionary\n",
    "month_dict.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4mYSeThzw7OY"
   },
   "source": [
    "####Finally ad one more columns, month_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34391,
     "status": "ok",
     "timestamp": 1554694292238,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "NgIsZB9Ww6my",
    "outputId": "ee62a159-5a4b-4197-e22c-5cceb2817c68"
   },
   "outputs": [],
   "source": [
    "for k,v in month_dict.items():\n",
    "  df_year.loc[(df_year['month'] == k), 'month_name'] = v \n",
    "df_year.head(), df_year.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eOHvLslMTz2u"
   },
   "source": [
    "### EDA\n",
    " - define uselful functions for visualizations\n",
    " - Plotting and visualizing features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cC9pxUInUYo9"
   },
   "source": [
    "#### Define plotting functions for looking at each month individually \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cPcTIgoDX4u-"
   },
   "source": [
    "##### def make_violinplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iR1kdhfiT8J_"
   },
   "outputs": [],
   "source": [
    "# plotting order totals per month in violin plots\n",
    "\n",
    "def make_violinplot(x,y, title=None, hue=None, ticklabels=None):\n",
    "  \n",
    "  '''Plots a violin plot with horizontal mean line, inner stick lines'''\n",
    "  \n",
    "  plt.style.use('dark_background')\n",
    "  fig,ax =plt.subplots(figsize=(8,6))\n",
    "\n",
    "\n",
    "  sns.violinplot(x, y,cut=2,split=True, scale='count', scale_hue=True,\n",
    "                 saturation=.5, alpha=.9,bw=.25, palette='Dark2',inner='stick', hue=hue).set_title(title)\n",
    "\n",
    "  ax.axhline(y.mean(),label='total mean', ls=':', alpha=.5, color='xkcd:yellow')\n",
    "  ax.set_xticklabels(ticklabels)\n",
    "\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "  x= df_year['month']\n",
    "  y= df_year['order_total']\n",
    "  title = 'Order totals per month with or without discounts'\n",
    "  hue=df_year['Discount']>0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ZXCOjzFbspu"
   },
   "source": [
    "##### def make-stripplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S9Yyn3cBbw7r"
   },
   "outputs": [],
   "source": [
    "def make_stripplot(x, y, title=None, hue=None, ticklabels=None):\n",
    "\n",
    "    plt.style.use('dark_background')\n",
    "    fig,ax =plt.subplots(figsize=(8,6))\n",
    "\n",
    "\n",
    "    sns.stripplot(x, y, jitter=True, size=12,edgecolor='gray',linewidth=1.5, alpha=.5, palette='Dark2',marker='d', hue=hue).set_title(title)\n",
    "\n",
    "    ax.axhline(y.mean(),label='total mean', ls=':', alpha=.5, color='xkcd:yellow')\n",
    "    ax.set_xticklabels(ticklabels)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cBrj92x2Us3C"
   },
   "source": [
    "##### def draw_histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3LvINQTiUO6y"
   },
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "def draw_histograms(df, variable, sample_dict, n_rows, n_cols):\n",
    "\n",
    "    '''Takes dataframe, variable is column name , plots histograms '''\n",
    "\n",
    "    with plt.style.context('seaborn-paper'):\n",
    "\n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "        for k,v in sample_dict.items():\n",
    "\n",
    "            month = df[df[variable] == k]['order_total']\n",
    "            month_mean = round(np.mean(month),2)\n",
    "\n",
    "            year =  df[df['month'] != k]['order_total']\n",
    "            year_mean = round(np.mean(year),2)\n",
    "\n",
    "            ax = fig.add_subplot(n_rows,n_cols,k)\n",
    "            ax.tick_params(labelsize=8)\n",
    "\n",
    "            plt.hist(year, bins=90,alpha=.7, label='Rest of Year')\n",
    "            plt.hist(month, alpha=.6,label= v.title())\n",
    "\n",
    "            ax.set_title(v.title(),fontsize=14)\n",
    "\n",
    "            plt.axvline(month_mean, color='xkcd:fuchsia',linestyle='--',\n",
    "                      label='Sample Mean \\n'+str(month_mean))\n",
    "\n",
    "            plt.axvline(year_mean,color='xkcd:green',linestyle='-',\n",
    "                      label='Pop. Mean \\n'+str(year_mean))\n",
    "\n",
    "            plt.legend(fontsize=6, frameon=False, ncol = 2 )\n",
    "\n",
    "        fig.tight_layout()    \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR6ajM4YVH3z"
   },
   "source": [
    "##### def draw_histograms_sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b290y-7DVQg_"
   },
   "outputs": [],
   "source": [
    "def draw_histograms_from_sample(population,sample_dict, n_rows, n_cols):\n",
    "\n",
    "    fig = plt.figure(figsize=(8.5,7.5))\n",
    "    count = 0\n",
    "\n",
    "    for k,v in sample_dict.items():\n",
    "    \n",
    "        count += 1                        \n",
    "\n",
    "        month = sample_dict[k] #pop_samp_month_dict[k]\n",
    "        month_mean = round(np.mean(v),2)\n",
    "\n",
    "        year = population\n",
    "        year_mean = round(np.mean(population),2)\n",
    "\n",
    "        ax = fig.add_subplot(n_rows,n_cols, count)\n",
    "        ax.tick_params(labelsize=8)\n",
    "\n",
    "        plt.hist(year, alpha=.8, label='All Months')\n",
    "        plt.hist(month, alpha=.6, label = k.title())\n",
    "\n",
    "        ax.set_title(k.title(),fontsize=14)\n",
    "\n",
    "        plt.axvline(month_mean, color='xkcd:fuchsia',linestyle='--',\n",
    "                    label='Sample Mean \\n'+str(month_mean))\n",
    "        plt.axvline(year_mean,color='xkcd:green',linestyle='-',\n",
    "                    label='Pop. Mean \\n'+str(year_mean))\n",
    "\n",
    "        plt.legend(fontsize=6, frameon=False)\n",
    "    \n",
    "    fig.tight_layout()    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m-IJsfaeZShd"
   },
   "source": [
    "#### plot initial order totals by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vWUI5areZg83"
   },
   "outputs": [],
   "source": [
    "#declare variables to be plotted\n",
    "\n",
    "x = df_year['month']\n",
    "y = df_year['order_total']\n",
    "ticks = [v for v in month_dict.values()] \n",
    "title = 'Order totals per month with or without discounts'\n",
    "hue = df_year['Discount']>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 688
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36987,
     "status": "ok",
     "timestamp": 1554694294919,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "600QfjFUZo0N",
    "outputId": "ab54e9b8-4537-4992-9690-ad938325de8b"
   },
   "outputs": [],
   "source": [
    "make_violinplot(x,y,title,hue, ticks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37815,
     "status": "ok",
     "timestamp": 1554694295778,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "yKstXyROa-5y",
    "outputId": "98cd7004-7735-40a3-ef34-95059643be31"
   },
   "outputs": [],
   "source": [
    "make_stripplot(x,y,title,hue,ticks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i4ODtjI71c03"
   },
   "source": [
    "## ***Aim 2 : Run final workflow for testing assumptions***\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xkFmrtPc1a8I"
   },
   "source": [
    "\n",
    "* ***Aim 2: Select the appropriate t-test based on tests for the assumptions of normality and homogeneity of variance.***\n",
    "    1. **Test for Normality**<br>\n",
    "        - [Normaltest/ D’Agostino and Pearson’s](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.normaltest.html)\n",
    "<br>\n",
    "        ```scipy.stats.normaltest```\n",
    "        - Shapiro-Wilik Test<br>\n",
    "        ```scipy.stats.shapiro```\n",
    "    2. **Test for Homogeneity of Variance**<br>\n",
    "        - [Levene's Test](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.levene.html)<br>         ```scipy.stats.levene```\n",
    "    3. **Choose appropriate test based upon 1. and 2.** \n",
    "        - [Mann Whitney U Test](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html)<br>  - non parametric equivalent of ANOVA)<br>\n",
    "    ```stats.mannwhitneyu```<br>\n",
    "        - Normal: 2 sample t-test\n",
    "        - Welch's t-test (Jeff)\n",
    "        \n",
    "    4.  Calculate effect size, post-hoc tukeys tests.\n",
    "        - Effect size: [cohen's d](https://stackoverflow.com/questions/21532471/how-to-calculate-cohens-d-in-python)\n",
    "          \n",
    "* ***Aim 3: To perform post-hoc pairwise comparisons for level of discount***      \n",
    " \n",
    "     \n",
    "    6. If significant result, follow up with post-hoc tests\n",
    "        - [Tukey's] https://www.statsmodels.org/stable/generated/statsmodels.stats.multicomp.pairwise_tukeyhsd.html)\n",
    "        ```statsmodels.stats.multicomp.pairwise_tukeyhsd```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7VAimpHrBRoL"
   },
   "source": [
    "### Aim 2.1: Test for Normality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GFMslgjQqhPW"
   },
   "source": [
    "#### Histograms month vs all months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1007
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44282,
     "status": "ok",
     "timestamp": 1554694302274,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "ORjoqjicqgxQ",
    "outputId": "2faf8bf8-bbb9-43b2-c7e2-06dfd60f85fd"
   },
   "outputs": [],
   "source": [
    "draw_histograms(df_year, 'month', month_dict, 4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oVpC31QUC9cg"
   },
   "outputs": [],
   "source": [
    "# create a dict to test stats\n",
    "dict_to_test ={}\n",
    "for month in list(df_year['month_name'].unique()):\n",
    "    dict_to_test[month] = df_year.groupby('month_name').get_group(month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hwvBZywE0V0B"
   },
   "source": [
    "####Test for Normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gqiBjl0W4SP_"
   },
   "outputs": [],
   "source": [
    "H3_tests = [['Group:','TestName','Test Purpose','stat','p', 'p < .05'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44258,
     "status": "ok",
     "timestamp": 1554694302296,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "34ds8zvRz-X7",
    "outputId": "57ae4342-d5c6-4f62-a831-32ac87cab35f"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import normaltest\n",
    "\n",
    "for month,  df  in dict_to_test.items(): #month = key, df = values\n",
    "\n",
    "    arrA = dict_to_test[month][['order_total']]\n",
    "\n",
    "    #1. Test for normality\n",
    "    test_purpose = 'Normality'\n",
    "    test_to_run = 'normaltest'\n",
    "\n",
    "    arrA = np.array(arrA)\n",
    "    \n",
    "\n",
    "    statA, pA = eval(test_to_run)(arrA)\n",
    "    \n",
    "    print(f'{month}:', statA, pA)\n",
    "    \n",
    "    H3_tests.append([month, test_to_run, test_purpose ,statA, pA, pA < .05])\n",
    "    \n",
    "arrB = np.array(df_year['order_total'])\n",
    "stat, p = eval(test_to_run)(arrB)\n",
    "H3_tests.append(['Total Pop', test_to_run, test_purpose,stat,p, p < .05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cNlFwil16GUb"
   },
   "source": [
    "### Aim 2.2 Test Homogneity of variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gp3XGOXh_j7l"
   },
   "source": [
    "####Levenes Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44237,
     "status": "ok",
     "timestamp": 1554694302298,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "WYGU5I1f6K2e",
    "outputId": "3f9e451e-f454-45b0-e36a-b9c3b116048e"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import levene\n",
    "\n",
    "for month,  df  in dict_to_test.items(): #month = key, df = values\n",
    "\n",
    "    arrA = dict_to_test[month][['order_total']]\n",
    "    arrB = df_year['order_total']\n",
    "\n",
    "    test_to_run = 'levene'\n",
    "    test_purpose = 'Equal Variance'\n",
    "\n",
    "    arrA = np.array(arrA)\n",
    "    arrB = np.array(arrB)\n",
    "\n",
    "    stat, p = eval(test_to_run)(arrA,arrB,center='median')\n",
    "    \n",
    "    print(f'{month}:', stat,p)\n",
    "    \n",
    "    H3_tests.append([f'{month} & pop', test_to_run, test_purpose ,stat, p, p < .05])\n",
    "\n",
    "\n",
    "\n",
    "# arrA = \n",
    "\n",
    "# stat,p = eval(test_to_run)(arrA,arrB,center='median')\n",
    "\n",
    "# H3_tests.append(['A&B',test_to_run,'Equal Var',stat,p, p < .05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 798
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44220,
     "status": "ok",
     "timestamp": 1554694302305,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "px5jEsSNaKtR",
    "outputId": "218cd5cd-6c09-4b40-a1fa-f4916adf8b1c"
   },
   "outputs": [],
   "source": [
    "list2df(H3_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x92oj_lYeAEv"
   },
   "source": [
    "### Aim 2.3 T-Test\n",
    "- Resample to compare results \n",
    "- Mann-Whitney U  because it is nonparametric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "09fpshCkejbw"
   },
   "source": [
    "#### Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6kzrsltegbb"
   },
   "outputs": [],
   "source": [
    "months = {v:df_year.loc[df_year['month']==k]['order_total'] for k,\n",
    "          v in month_dict.items()}\n",
    "\n",
    "totals = df_year['order_total']\n",
    "\n",
    "n = 30 #number of points per sample drawn each loop\n",
    "i = 10000 #number of loops to draw sample populations\n",
    "\n",
    "pop_samp_month_dict = {}#dict to store each months random sample means\n",
    "\n",
    "pop_samp_order_total = []#container for populations random sample means\n",
    "\n",
    "for k,v in months.items(): #create a list for each month in dict,\n",
    "                            \n",
    "    pop_samp_month_dict[k] = []\n",
    "    \n",
    "    for i in range(0,i): #do 10000 loops drawing 30 random samples\n",
    "#append mean samples to above list for each month\n",
    "            \n",
    "        pop_samp_month_dict[k].append(round(v.sample(n=n).mean(),2))\n",
    "                        \n",
    "for i in range(0,i):#do the same for the whole pop as we just did for each month\n",
    "    \n",
    "    pop_samp_order_total.append(totals.sample(n=n).mean())\n",
    "    \n",
    "#Choose 1000 random mean samples to use to test hypothesis \n",
    "\n",
    "pop_samp_month_dict = {k:np.random.choice(pop_samp_month_dict[k],1000) for k,\n",
    "                   v in pop_samp_month_dict.items()}\n",
    "\n",
    "#same for population\n",
    "\n",
    "pop_samp_order_total = np.random.choice(pop_samp_order_total, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JUq9rj0-gQua"
   },
   "source": [
    "##### Historgrams of resamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 757
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4014,
     "status": "ok",
     "timestamp": 1554694675204,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "ZEY8jcIvfBnQ",
    "outputId": "bcd476f4-fa51-42f1-89d8-6ac82daa7243"
   },
   "outputs": [],
   "source": [
    "plt.style.context('dark_backm')\n",
    "draw_histograms_from_sample(pop_samp_order_total, pop_samp_month_dict, 4,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "31HioqKghRCr"
   },
   "source": [
    "##### Re-test homogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3997,
     "status": "ok",
     "timestamp": 1554694675205,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "CkirOf--iRYz",
    "outputId": "fffe0211-687f-4b99-9744-ab1ee1835cc1"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import levene\n",
    "\n",
    "arrA = [pop_samp_month_dict[k] for k,v in pop_samp_month_dict.items()]\n",
    "arrB = pop_samp_order_total\n",
    "\n",
    "test_to_run = 'levene'\n",
    "test_purpose = 'Equal Variance'\n",
    "\n",
    "stat,p = eval(test_to_run)(arrA[0],arrA[1],arrA[2],arrA[3],arrA[4],arrA[5]\n",
    "                           ,arrA[6],arrA[7],arrA[8],arrA[9],arrA[10],\n",
    "                           arrA[11],arrB,center='mean')\n",
    "\n",
    "H3_tests.append(['A&B Resampled',test_to_run,'Equal Var',stat,p])\n",
    "print(stat, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qdeuhELRgbMy"
   },
   "source": [
    "#####T- Test resampled populations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3971,
     "status": "ok",
     "timestamp": 1554694675206,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "NPW6sFdLhpFH",
    "outputId": "4647b3b5-9437-4c82-80d9-6baa16ba76cd"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "for k, v  in pop_samp_month_dict.items(): \n",
    "\n",
    "    arrA = pop_samp_month_dict[k]\n",
    "    arrB = pop_samp_order_total\n",
    "\n",
    "    test_to_run = 'ttest_ind'\n",
    "    test_purpose = 'H1 signifigance'\n",
    "\n",
    "\n",
    "    stat,p = eval(test_to_run)(arrA,arrB,equal_var=False)\n",
    "\n",
    "    print(f'{k}:',stat, p)\n",
    "\n",
    "    H3_tests.append([f'{k} & pop', test_to_run, test_purpose ,stat, p, p < .05])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P1mYMQLXGuU9"
   },
   "source": [
    "## Conclusions so far...\n",
    "- We failed both normaltests and homo variance\n",
    "the results for resampling do not seem reliable because they are being compared against them selfs\n",
    "- Will try non-parametric 2sample ttest\n",
    "    - [**Mann-Whitney U test**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html)\n",
    "  - Most likey the tukeys test will be the best test for signifigance of these samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CEdSVdVRgmjG"
   },
   "source": [
    "####Mann-Whitney U test\n",
    "- non parametric test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3962,
     "status": "ok",
     "timestamp": 1554694675209,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "GFWsPYW24Afm",
    "outputId": "3611e514-c676-45d4-f039-af17ed1912a5"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "for month, df  in dict_to_test.items(): #month = key, df = values\n",
    "\n",
    "    arrA = dict_to_test[month]['order_total']\n",
    "    arrB = df_year.loc[df_year['month_name']!= month,'order_total']\n",
    "\n",
    "    test_to_run = 'mannwhitneyu'\n",
    "    test_purpose = 'Hi sig.'\n",
    "\n",
    "    arrA = np.array(arrA).reshape(-1,1)\n",
    "    arrB = np.array(arrB).reshape(-1,1)\n",
    "\n",
    "    stat, p = eval(test_to_run)(arrA,arrB,alternative='two-sided')\n",
    "    \n",
    "    print(f'{month}:',stat, p)\n",
    "    \n",
    "    H3_tests.append([f'{month}', test_to_run, test_purpose ,stat, p, p < .05]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pnd2X_DWArZh"
   },
   "source": [
    "###Aim 2.4 Test effect size\n",
    " - use cohens d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3950,
     "status": "ok",
     "timestamp": 1554694675211,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "NchRG4PQA0Um",
    "outputId": "79f96ee3-49fa-4768-82aa-ffc339dec1a2"
   },
   "outputs": [],
   "source": [
    "d_dict = {}\n",
    "for month,  df  in dict_to_test.items(): #month = key, df = values\n",
    "\n",
    "    arrA = dict_to_test[month][['order_total']]\n",
    "    arrB = df_year[df_year['month_name']!= month]['order_total']\n",
    "\n",
    "    test_to_run = 'Cohen_d'\n",
    "    test_purpose = 'efect Size'\n",
    "\n",
    "    arrA = np.array(arrA)\n",
    "    arrB = np.array(arrB)\n",
    "\n",
    "    d = Cohen_d(arrA, arrB)\n",
    "    \n",
    "    d_dict[month] = d\n",
    "    \n",
    "    print(f'{month}:',d)\n",
    "    H3_tests.append([f'{month}', test_to_run, test_purpose ,stat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gKdARiCMDmw0"
   },
   "source": [
    "####View all test results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1907
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3916,
     "status": "ok",
     "timestamp": 1554694675212,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "0OVY01SMRD_l",
    "outputId": "cfd146d1-2a4f-41a4-8370-1d6894bfb866"
   },
   "outputs": [],
   "source": [
    "#put results in DataFrame\n",
    "list2df(H3_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fhPYorQYBRof"
   },
   "source": [
    "#### Calculating Effect Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3897,
     "status": "ok",
     "timestamp": 1554694675213,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "YNNnHq2TBRof",
    "outputId": "15da2544-f61b-40bb-9895-b8ae962b31f9"
   },
   "outputs": [],
   "source": [
    "# Calculating Cohens d\n",
    "d = Cohen_d(arrA,arrB)\n",
    "print(f\"Cohen's d={round(d,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tlxz4CgRBRoj"
   },
   "source": [
    "## ***Aim 3: Compare between all Months***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y2MPDv3PCqdG"
   },
   "source": [
    "####Tukey's Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xIHLn1gqEe57"
   },
   "outputs": [],
   "source": [
    "# Importing tukey's test\n",
    "\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd as tukey\n",
    "\n",
    "int_str = [str(x) for x in df_year['month_name']]# create labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NF-3vbMb3ofW"
   },
   "outputs": [],
   "source": [
    "#run tukeys test\n",
    "tukey_results =tukey(df_year['order_total'], int_str, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1907
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4369,
     "status": "ok",
     "timestamp": 1554694675735,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "j6-3co5F1NWz",
    "outputId": "cb74a6df-8058-4982-c7be-80274d156140"
   },
   "outputs": [],
   "source": [
    "# Save the results into a dataframe\n",
    "\n",
    "dfH_tukey = pd.DataFrame(data=tukey_results._results_table.data[1:],\n",
    "                         columns=tukey_results._results_table.data[0])\n",
    "\n",
    "# checking for any signifigance\n",
    "dfH_tukey.loc[dfH_tukey['reject']==True]\n",
    "dfH_tukey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3JKcx3pw5_LK"
   },
   "source": [
    "## ***Conclusions for Hypothesis 3:***\n",
    "1. **We first used D'Agostino & Perason's test (normaltest) to check for normal distributions**\n",
    "    -  Both groups had p-values very far below our $\\alpha=0.05$  (Rows 0,1 below)\n",
    "        - We rejecteded the null hypothesis that the groups came from a populatiin with a normal distribtuion. \n",
    "2. **We tested for equal variances using Levene's test. **\n",
    "    - Level's test had a signifcant p-value, so we rejected the hypothesis that the groups have equal variances\n",
    "    \n",
    "3. **We then concluded we need a non-parametric 2-sample test, so we used the Mann-Whitney U test**. \n",
    "    -  Our comparison had a p-value less than .05\n",
    "    - We reject the null hypothesis that discounts do not affect quantities sold.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4sBXbyOoiizm"
   },
   "source": [
    "# Hypothesis 4 \n",
    "\n",
    "$H_1$ the difference between discounted and non discounted quantities purchased is the ***same ***per country\n",
    "\n",
    "$H_0$ : The difference between discouted and non discounted quantities purchased is ***different*** per country\n",
    "\n",
    "**Specific Aims:**\n",
    "\n",
    "* ***Aim 1:To select the proper dataset for analysis, perform EDA, and generate data groups for testing.***\n",
    "    - Used sqlalchemy and pandas.read_sql_query()\n",
    "    query = \n",
    "\n",
    "* ***Aim 2: Select the appropriate t-test based on tests for the assumptions of normality and homogeneity of variance.***\n",
    "    1. **Test for Normality**\n",
    "        - D'Agostino-Pearson's normality test<br>\n",
    "        ```scipy.stats.normaltest```\n",
    "        - Shapiro-Wilik Test<br>\n",
    "        ```scipy.stats.shapiro```\n",
    "    2. **Test for Homogeneity of Variance**\n",
    "        - Levene's Test<br>\n",
    "         ```scipy.stats.levene```\n",
    "\n",
    "    3. **Choose appropriate test based upon 1. and 2.** \n",
    "\n",
    "\n",
    "* ***Aim 3: To perform post-hoc painrwise comparison testing to determine which level of discounts affect quantity and if any discount has a greater effect than the others.***\n",
    "     - Tukey's test for multiple pairwise comparisons\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l2FuFCGTm1MC"
   },
   "source": [
    "## ***Aim 1.1 : To select the proper dataset for analyiss  and generate data groups for testing.***\n",
    "\n",
    "#### Importing Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 797
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 528,
     "status": "ok",
     "timestamp": 1554695337462,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "EFzIGeuLnF6N",
    "outputId": "a6a2f5ec-d45c-435c-8443-431acb00bcfc"
   },
   "outputs": [],
   "source": [
    "DB_Order = pd.read_sql_table('Order',engine);\n",
    "DB_OrderDetail = pd.read_sql_table('OrderDetail',engine);\n",
    "print(f\"DB_Order columns:{DB_Order.columns}n\\n DB_OrderDetail columns: {DB_OrderDetail.columns}\")#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ajT5x1OGna0r"
   },
   "source": [
    "#####def df_drop_regex( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HjwrhazvnJKy"
   },
   "outputs": [],
   "source": [
    "def df_drop_regex(DF, regex_list):\n",
    "    '''Use a list of regex to remove columns names. Returns new df.\n",
    "    \n",
    "    Parameters:\n",
    "        DF -- input dataframe to remove columns from.\n",
    "        regex_list -- list of string patterns or regexp to remove.\n",
    "    \n",
    "    Returns:\n",
    "        df_cut -- input df without the dropped columns. \n",
    "        '''\n",
    "    df_cut = DF.copy()\n",
    "    \n",
    "    for r in regex_list:\n",
    "        \n",
    "        df_cut = df_cut[df_cut.columns.drop(list(df_cut.filter(regex=r)))]\n",
    "        print(f'Removed {r}\\n')\n",
    "        \n",
    "    return df_cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sYWrrIWknysC"
   },
   "source": [
    "##### set up new df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1203,
     "status": "ok",
     "timestamp": 1554695352618,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "OhR_TEfMniRN",
    "outputId": "d6cf4645-84f3-492e-89a6-25f2e6267694"
   },
   "outputs": [],
   "source": [
    "# TAKE  DB_Orderm rename index, remove unwanted columns\n",
    "DB_Order.rename({'Id':'OrderId','OrderDate':'OrderPlaced'},axis=1,inplace=True)\n",
    "\n",
    "# Drop unwanted columns from DB_Orde to make df_Order\n",
    "regex_to_drop = ['Date','Freight']\n",
    "\n",
    "df_Order = df_drop_regex(DB_Order, regex_to_drop)\n",
    "df_Order.rename({'OrderPlaced':'OrderDate'},axis=1,inplace=True)\n",
    "df_Order.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KKBb0MH0n5T6"
   },
   "outputs": [],
   "source": [
    "# MERGING IMPORT DB_OrderDetail and cleaned df_Order\n",
    "df_merged = DB_OrderDetail.merge(df_Order, on='OrderId',copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mQQSXI5Yopsh"
   },
   "outputs": [],
   "source": [
    "df_order_geo = df_merged.copy()\n",
    "# df_order_geo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6RTTGUaNpXUG"
   },
   "outputs": [],
   "source": [
    "#Apply calc_product_price to every row \n",
    "df_price_geo = df_order_geo.apply(lambda x: calc_product_price(x),\n",
    "                                  axis=1)\n",
    "\n",
    "# Apply_calc_order_total to every row\n",
    "df_price_geo = df_price_geo.apply(lambda x: calc_order_total(x,df_price_geo),\n",
    "                                  axis=1) \n",
    "# df_price_geo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10785,
     "status": "ok",
     "timestamp": 1554695362264,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "IDqck62kqOYM",
    "outputId": "7d2f3edf-d388-4d78-b5db-41fcd0009776"
   },
   "outputs": [],
   "source": [
    "#Convert to Datetime\n",
    "df_price_geo['OrderDate'] = pd.to_datetime(df_price_geo.OrderDate )\n",
    "df_price_geo.OrderDate.agg(['mean','max','min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3YUSPx_Pqtln"
   },
   "outputs": [],
   "source": [
    "#create new columns for week_day and month\n",
    "df_price_geo['OrderDate'] = pd.to_datetime(df_price_geo.OrderDate)\n",
    "\n",
    "df_price_geo['week_day'] = df_price_geo['OrderDate'].dt.dayofweek\n",
    "df_price_geo['month'] = df_price_geo['OrderDate'].dt.month\n",
    "\n",
    "# df_price_geo.info()#Check for new columns and ensure pd.datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4jTZ5_Gq1UY"
   },
   "outputs": [],
   "source": [
    "##make list of month names (strings) \n",
    "months = ['jan','feb', 'mar', 'apr', 'may' , 'jun',\n",
    "          'jul', 'aug', 'sep', 'oct', 'nov', 'dec']#creating label names\n",
    "\n",
    "# month_code =\n",
    "month_dict = dict(zip( list(range(1,len(months)+1)),months)) #zip the two into a dictionary\n",
    "\n",
    "# MAP THE MONTH_DICT ONTO NEW COLUMN month_name\n",
    "df_price_geo['month_name'] = df_price_geo['month'].map(month_dict)\n",
    "# df_price_geo['month_name'].value_counts()#checking how many of each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10740,
     "status": "ok",
     "timestamp": 1554695362273,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "YyfViCaVq7um",
    "outputId": "1b14b6e7-b9b0-4fb9-a010-0aa388991b63"
   },
   "outputs": [],
   "source": [
    "df_price_geo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10714,
     "status": "ok",
     "timestamp": 1554695362274,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "fWo4s3nQjJ5c",
    "outputId": "640b3326-4586-4a39-9b63-963a188fc49b"
   },
   "outputs": [],
   "source": [
    "#renamed df for ease of typing & it is a comprehensize starting point\n",
    "df = df_price_geo\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bGkumAfqrQYU"
   },
   "source": [
    "####Engineering new features\n",
    "- difference between quantity bought with and without discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10946,
     "status": "ok",
     "timestamp": 1554695362575,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "xpPmlAPTrxra",
    "outputId": "b1de4b5c-6570-4f06-95c8-f5fc34f5ab89"
   },
   "outputs": [],
   "source": [
    "#Create New features for working exploring discount effects on sales\n",
    "D_country = {}\n",
    "\n",
    "countries = list(df['ShipCountry'].unique())\n",
    "\n",
    "for country in countries:\n",
    "    \n",
    "#check for discounts    \n",
    "    check_if_discounted = len(df.groupby('ShipCountry').get_group(country)['OnSale'].unique())\n",
    "    \n",
    "    if check_if_discounted < 2:\n",
    "        print(f'{country} did not have both discounted and non-discounted items.')\n",
    "        continue\n",
    "        \n",
    "    else:\n",
    "        \n",
    "#Organize prices based on sales and fullprice    \n",
    "        D_country[country]={}\n",
    "\n",
    "        D_country[country]['df_sale'] = df.loc[df['OnSale']==1].groupby('ShipCountry').get_group(country)\n",
    "        D_country[country]['df_fullprice'] = df.loc[df['OnSale']==0].groupby('ShipCountry').get_group(country)\n",
    "        \n",
    "#Get total sales\n",
    "        D_country[country]['price']={}\n",
    "        D_country[country]['price']['OnSale'] = D_country[country]['df_sale']['price']\n",
    "        D_country[country]['price']['FullPrice'] = D_country[country]['df_fullprice']['price']\n",
    "        \n",
    "#Get Quantity sold at discount/nondiscount\n",
    "        D_country[country]['quantity']={}\n",
    "        D_country[country]['quantity']['OnSale'] = D_country[country]['df_sale']['Quantity']\n",
    "        D_country[country]['quantity']['FullPrice'] = D_country[country]['df_fullprice']['Quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 618
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 511,
     "status": "ok",
     "timestamp": 1554696199133,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "AC3EWhD2uRw6",
    "outputId": "f7cca7f3-bd56-4e63-d40b-4fce24a9810c"
   },
   "outputs": [],
   "source": [
    "dC = D_country\n",
    "\n",
    "# price_sale-full = []\n",
    "# results = pd.DataFrame()\n",
    "\n",
    "results = [['country','Price_Disc-Full','Price_Disc/Total','Quant_Disc-Full',\n",
    "            'Quant_Disc/Total','AvgPrice_Disc','AvgPrice_Full','AvgPrice/item']]\n",
    "\n",
    "for c in dC.keys():\n",
    "    \n",
    "    temp = ['country','Price_Disc-Full','Price_Disc/Total','Quant_Disc-Full',\n",
    "            'Quant_Disc/Total','AvgPrice_Disc','AvgPrice_Full','AvgPrice/item']\n",
    "    \n",
    "    calc = dC[c]\n",
    "    \n",
    "    i=0\n",
    "# country name\n",
    "    temp[i] = c\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "#price sub\n",
    "    temp[i] = (calc['price']['OnSale'].sum() -\n",
    "               calc['price']['FullPrice'].sum())\n",
    "    i+=1\n",
    "    \n",
    "# price/total\n",
    "    temp[i] =  (calc['price']['OnSale'].sum() / \n",
    "                (calc['price']['FullPrice'].sum() +\n",
    "                 calc['price']['OnSale'].sum()))\n",
    "    i+=1\n",
    "    \n",
    "# quantitty sub\n",
    "    temp[i] = (calc['quantity']['OnSale'].sum() -\n",
    "               calc['quantity']['FullPrice'].sum())\n",
    "    i+=1\n",
    "    \n",
    "# quantity total\n",
    "    temp[i] = (calc['quantity']['OnSale'].sum() / \n",
    "               (calc['quantity']['FullPrice'].sum() +\n",
    "                calc['quantity']['OnSale'].sum()))\n",
    "    i+=1\n",
    "    \n",
    "# average spent on sale items\n",
    "    temp[i] = (calc['price']['OnSale'].sum() /\n",
    "               calc['quantity']['OnSale'].sum() )\n",
    "    i+=1\n",
    "    \n",
    "# average spent on full price items\n",
    "    temp[i] = (calc['price']['FullPrice'].sum()  /\n",
    "               calc['quantity']['FullPrice'].sum()) \n",
    "    i+=1\n",
    "    \n",
    "# average spent on all items\n",
    "    temp[i] = (calc['price']['FullPrice'].sum() + \n",
    "               calc['price']['OnSale'].sum() /\n",
    "               calc['quantity']['FullPrice'].sum() + \n",
    "               calc['quantity']['OnSale'].sum())\n",
    "    \n",
    "    results.append(temp)\n",
    "\n",
    "df_countries = list2df(results)\n",
    "\n",
    "df_countries.set_index('country',inplace=True)\n",
    "\n",
    "df_countries.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11271,
     "status": "ok",
     "timestamp": 1554695362936,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "PYjuUqhtu3y0",
    "outputId": "58e74a38-c199-40b2-a02f-a1aea0113a11"
   },
   "outputs": [],
   "source": [
    "cleaned = pd.DataFrame(df.drop_duplicates(['OrderId']))\n",
    "\n",
    "# Making average price of sales for each country\n",
    "\n",
    "df_countries['AvgOrderPrice'] = (cleaned.groupby\n",
    "                                 ('ShipCountry')['order_total'].mean())\n",
    "\n",
    "\n",
    "#Column that shows percentage of total sales from each country\n",
    "\n",
    "df_countries['PctOf-orders'] = round((cleaned.groupby\n",
    "                                      ('ShipCountry')['OrderId'].count() /\n",
    "                                      cleaned['OrderId'].count().sum()*\n",
    "                                                                100),2)\n",
    "\n",
    "#percentage of total income\n",
    "\n",
    "df_countries['PctOf-Income'] = round((cleaned.groupby\n",
    "                                      ('ShipCountry')['order_total'].sum() / \n",
    "                                      cleaned['order_total'].sum()*100),2)\n",
    "\n",
    "#Checking results, Three countries had no disc.\n",
    "\n",
    "print(df_countries['PctOf-orders'].sum(),\n",
    "      df_countries['PctOf-Income'].sum()) \n",
    "\n",
    "\n",
    "#comparing percentage of all orders vs percentage on overall income \n",
    "\n",
    "df_countries['orders2-Income'] = (df_countries['PctOf-orders'] /\n",
    "                                  df_countries['PctOf-Income'])\n",
    "\n",
    "\n",
    "#finding difference between full price and disc price\n",
    "\n",
    "df_countries['DiscountGap'] = (df_countries['AvgPrice_Full'] -\n",
    "                               df_countries['AvgPrice_Disc'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7-QR1qduvk5G"
   },
   "source": [
    "####EDA of new values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sVERvm2szQi8"
   },
   "outputs": [],
   "source": [
    "# Add stats to df\n",
    "df_header = df_countries.columns\n",
    "\n",
    "country_col_means = pd.Series(df_countries.mean(axis=0)) # Mean\n",
    "country_col_sem = pd.Series(df_countries.sem(axis=0))   # Std. Error Mean\n",
    "country_col_std = pd.Series(df_countries.std(axis=0))  # Std. deviation\n",
    "\n",
    "\n",
    "df_test = pd.DataFrame([country_col_means, country_col_sem,\n",
    "                        country_col_std],columns=df_header)\n",
    "\n",
    "df_test.index = ['mean','sem','std']\n",
    "\n",
    "df_countries = pd.concat([df_countries, df_test])# adding stats to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11243,
     "status": "ok",
     "timestamp": 1554695362939,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "_a6_niM2it8j",
    "outputId": "8b448d6e-7fe5-4083-980c-3f7645a8b626"
   },
   "outputs": [],
   "source": [
    "#Create different criterila for exploring and anaqlyzing the current df\n",
    "\n",
    "\n",
    "crit = ((df_countries['orders2-Income'] < 1) &\n",
    "        (df_countries['AvgOrderPrice'] > 1488.357771))\n",
    "\n",
    "crit2=((df_countries['AvgPrice_Full']> 25.907391) &\n",
    "       (df_countries['AvgPrice_Disc']> 22.236349))\n",
    "\n",
    "# Used this for determining the countries usedin hypothesis 4\n",
    "\n",
    "crit3 = (df_countries['Quant_Disc/Total'] > 0.433410) #Going with this\n",
    "\n",
    "winning = df_countries.loc[crit3]\n",
    "losing = df_countries.loc[~crit3]\n",
    "\n",
    "winning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11226,
     "status": "ok",
     "timestamp": 1554695362941,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "23BtdAIDREal",
    "outputId": "933f6d6f-eaf1-45a3-e25e-977e944fe1b7"
   },
   "outputs": [],
   "source": [
    "losing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11207,
     "status": "ok",
     "timestamp": 1554695362942,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "7cE5vjvB1rgM",
    "outputId": "dc2c429a-4fbd-47e6-a6a8-aa906e156901"
   },
   "outputs": [],
   "source": [
    "print(winning.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5821
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15083,
     "status": "ok",
     "timestamp": 1554695366836,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "nfbppy4h6Gmv",
    "outputId": "b8a6a4b1-8c79-492d-a299-758655f99410"
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "for col in winning.columns:\n",
    "    fig = plt.figure()\n",
    "\n",
    "    plt.bar(x=winning.index, height=winning[col],yerr=df_test.loc['sem',col])#,**bar_kws)\n",
    "    ax = fig.gca()\n",
    "    ax.set_xticklabels(winning.index, rotation=75)\n",
    "    ax.set_ylabel(col)\n",
    "    plt.tight_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fhbVU_l_vScd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5823
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20238,
     "status": "ok",
     "timestamp": 1554695372022,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "6g3AhpUq_SvW",
    "outputId": "19d3aac9-613f-4d87-8044-453593f3d7e2"
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "for col in df_countries.columns:\n",
    "    fig = plt.figure()\n",
    "\n",
    "    plt.bar(x=df_countries.index, height=df_countries[col],yerr=df_test.loc['sem',col])#,**bar_kws)\n",
    "    ax = fig.gca()\n",
    "    ax.set_xticklabels(df_countries.index, rotation=75)\n",
    "    ax.set_ylabel(col)\n",
    "    plt.tight_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20719,
     "status": "error",
     "timestamp": 1554695372523,
     "user": {
      "displayName": "Michael Moravetz",
      "photoUrl": "",
      "userId": "00349170578877048894"
     },
     "user_tz": 240
    },
    "id": "Lzp8htnyv-A4",
    "outputId": "65cdfb86-a343-4fc7-c9e9-914188fca88a"
   },
   "outputs": [],
   "source": [
    "# plt.style.use('ggplot')\n",
    "# bar_kws = {'figsize':[6,4],\n",
    "#           'title': 'Order Totals By Month',\n",
    "#           'grid':False,\n",
    "#           'legend':False,\n",
    "#           'rot':45,\n",
    "#            'yerr':'sem',\n",
    "#           'ylim': [0,2500]}\n",
    "\n",
    "# fig = df_country.plot(kind='bar',x=df_country['qu'].index.str.title(),y='mean',**bar_kws)#,table=True)\n",
    "# fig.set(**{'xlabel':'Month','ylabel':'Order Total($)'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oZvTI3muR0bK"
   },
   "source": [
    "## Hypothesis 4\n",
    "- $H0$ - Orders shipped to countries with a higher than average price for discounted items Have  no different average order total compared to all other months\n",
    "\n",
    "$H1$ - Orders shipped to countries with higher than average discounted sales prices per item do have higher order totals.\n",
    "\n",
    "  - I am defining countries with higher than average discount prices as the following:\n",
    "   Brazil, Belgium, Austria', Mexico, USA, Sweden, Spain, Ireland, Canada, Denmark.\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_juPXPMG0umc"
   },
   "outputs": [],
   "source": [
    "df_c =df.drop_duplicates('OrderId')\n",
    "df_c.head()\n",
    "df_c.set_index('OrderId',inplace=True)\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a1L8CizZNV2U"
   },
   "outputs": [],
   "source": [
    "countries = list(df['ShipCountry'].unique())\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PcplPtK4OnxF"
   },
   "outputs": [],
   "source": [
    "# df_c.['Above_av_disc'].map(x:) \n",
    "#make list of month names (strings) \n",
    "countries = {'France':1,\n",
    " 'Germany':1,\n",
    " 'Brazil':1,\n",
    " 'Belgium':0,\n",
    " 'Switzerland':1,\n",
    " 'Venezuela':0,\n",
    " 'Austria':1,\n",
    " 'Mexico':0,\n",
    " 'USA':1,\n",
    " 'Sweden':1,\n",
    " 'Finland':0,\n",
    " 'Italy':1,\n",
    " 'Spain':1,\n",
    " 'UK':0,\n",
    " 'Ireland':1,\n",
    " 'Portugal':1,\n",
    " 'Canada':1,\n",
    " 'Denmark':0,\n",
    " 'Poland':0,\n",
    " 'Norway':0,\n",
    " 'Argentina':0}#creating label names\n",
    "# 'France', 'Germany', 'Brazil', 'Switzerland', 'Austria', 'USA',\n",
    "#        'Sweden', 'Italy', 'Ireland', 'Portugal', 'Canada', \n",
    "\n",
    "# MAP THE MONTH_DICT ONTO NEW COLUMN country name\n",
    "df_c['Abovecrit'] = df_c['ShipCountry'].map(countries)\n",
    "\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T_X-Y2n8Q-WC"
   },
   "outputs": [],
   "source": [
    "h4_samp = df_c.groupby('Abovecrit')['order_total'].get_group(1)\n",
    "h4_pop = df_c.groupby('Abovecrit')['order_total'].get_group(0)\n",
    "# pd.DataFrame(h4_samp).info()\n",
    "print(h4_pop.mean(),h4_samp.mean())\n",
    "h4_pop= pd.DataFrame(h4_pop)\n",
    "h4_samp= pd.DataFrame(h4_samp)\n",
    "h4_samp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vdc7jPWoRoJV"
   },
   "source": [
    "### Going back to the original df to test the hypthesis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrQWLjFdWH3-"
   },
   "outputs": [],
   "source": [
    "plot_wide_kde_thin_bar(h4_samp.order_total, '40%+ dic/total',h4_pop.order_total,'Populatioin')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4yeaaxcTi4L6"
   },
   "outputs": [],
   "source": [
    "with plt.style.context(('dark_background')):\n",
    "    sns.set_palette('Dark2')\n",
    "    fig = plt.figure()\n",
    "    plt.title('Distribution of total order price for orders with an average or 40% discounted Items ')\n",
    "\n",
    "    disc = h4_samp['order_total']\n",
    "    full = h4_pop['order_total']\n",
    "    \n",
    "    \n",
    "    plt.hist(full, alpha = 0.8, bins=30,label='less than 40$ discounted on average')\n",
    "    plt.hist(disc, alpha = 0.5, bins=30,label='Discounted')\n",
    "\n",
    "    # Adding annotations\n",
    "    meanD = round(np.mean(disc),3)\n",
    "    meanF = round(np.mean(full),3)\n",
    "    \n",
    "    plt.axvline(meanD, color='green',linestyle='--',label='Discounted Mean')\n",
    "    plt.text(meanD,190,f'Mean:{meanD}',rotation=270,fontweight='medium')\n",
    "    \n",
    "    plt.axvline(meanF,color='white',linestyle='-',label='Full Price Mean')\n",
    "    plt.text(meanF, 190, f'Mean:{meanF}',rotation=270,fontweight='medium')\n",
    "\n",
    "    plt.xlabel('order_total')\n",
    "    plt.ylabel('Counts')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VaCHDOE5z8w9"
   },
   "outputs": [],
   "source": [
    "# x = df_c.loc[df_c['Abovecrit'], 'ShipCountry']\n",
    "# x\n",
    "# make_stripplot(df_c['Abovecrit']['ShipCountry'],df_c[\"order_total\"]\n",
    "#                ,title='Countries with avg 40% discount items/order', \n",
    "#                hue= df_countries['orders2-Income'] > 1,\n",
    "#                ticklabels = df_c['Abovecrit'])\n",
    "# make_stripplot(x, y, title=None, hue=None, ticklabels=None):\n",
    "\n",
    "#     plt.style.use('dark_background')\n",
    "#     fig,ax =plt.subplots(figsize=(8,6))\n",
    "\n",
    "\n",
    "#     sns.stripplot(x, y, jitter=True, size=12,edgecolor='gray',linewidth=1.5, alpha=.5, palette='Dark2',marker='d', hue=hue).set_title(title)\n",
    "\n",
    "#     ax.axhline(y.mean(),label='total mean', ls=':', alpha=.5, color='xkcd:yellow')\n",
    "#     ax.set_xticklabels(ticklabels)\n",
    "\n",
    "#     plt.legend()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1jE5N45IlO1j"
   },
   "source": [
    "##Check for normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qQXH9mCNlWU5"
   },
   "outputs": [],
   "source": [
    "H4_tests = [['Group:','TestName','Test Purpose','stat','p', 'p < .05'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LCvpo7j9mzyr"
   },
   "source": [
    "####Normal test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X0VbLUVckl6e"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import normaltest\n",
    "\n",
    "\n",
    "arrA = h4_samp.order_total\n",
    "arrB =h4_pop.order_total\n",
    "\n",
    "#1. Test for normality\n",
    "test_purpose = 'Normality'\n",
    "test_to_run = 'normaltest'\n",
    "\n",
    "arrA = np.array(arrA)\n",
    "arrB = np.array(arrB)\n",
    "\n",
    "\n",
    "statA, pA = eval(test_to_run)(arrA)\n",
    "stat, p = eval(test_to_run)(arrB)\n",
    "\n",
    "print('samp:', statA, pA,'\\n''pop:',stat,p)\n",
    "\n",
    "H4_tests.append(['Sample', test_to_run, test_purpose ,statA, pA, pA < .05])\n",
    "H4_tests.append(['Total Pop', test_to_run, test_purpose,stat,p, p < .05])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2g9lByASm7AM"
   },
   "source": [
    "### Check variance \n",
    "- levenes test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HDLkN78smpda"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import levene\n",
    "\n",
    "\n",
    "arrA = h4_samp.order_total\n",
    "arrB =h4_pop.order_total\n",
    "\n",
    "test_to_run = 'levene'\n",
    "test_purpose = 'Equal Variance'\n",
    "\n",
    "arrA = np.array(arrA)\n",
    "arrB = np.array(arrB)\n",
    "\n",
    "stat, p = eval(test_to_run)(arrA,arrB,center='median')\n",
    "\n",
    "print('sample and pop:', stat,p)\n",
    "\n",
    "H4_tests.append(['sample & pop', test_to_run, test_purpose ,stat, p, p < .05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gNboFKXIoYOf"
   },
   "source": [
    "## T-test\n",
    "- Both sample and population are not normal and dont have equal variance.\n",
    "- use Whitney-Mann U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CzXgYdAlo2Uu"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "arrA = h4_samp.order_total\n",
    "arrB =h4_pop.order_total\n",
    "\n",
    "test_to_run = 'mannwhitneyu'\n",
    "test_purpose = 'Hi sig.'\n",
    "\n",
    "arrA = np.array(arrA)#.reshape(-1,1)\n",
    "arrB = np.array(arrB)#.reshape(-1,1)\n",
    "\n",
    "stat, p = eval(test_to_run)(arrA,arrB,alternative='greater')\n",
    "\n",
    "print('sample and pop:', stat, p)\n",
    "\n",
    "H4_tests.append(['sample and pop', test_to_run, test_purpose ,stat, p, p < .05]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nz2OFLkdqbE9"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "                  \n",
    "arrA = h4_samp.order_total\n",
    "arrB =h4_pop.order_total\n",
    "\n",
    "test_to_run = \"ttest_ind\"\n",
    "test_purpose = 'signifigance'\n",
    "\n",
    "arrA = np.array(arrA)#.reshape(-1,1)\n",
    "arrB = np.array(arrB)#.reshape(-1,1)\n",
    "\n",
    "stat, p = eval(test_to_run)(arrA,arrB,equal_var=False)\n",
    "p = p /2\n",
    "\n",
    "print('sample and pop:', stat, p)\n",
    "\n",
    "H4_tests.append(['sample and pop', test_to_run, test_purpose ,stat, p, p < .05])     \n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NbFuJFZozz2o"
   },
   "outputs": [],
   "source": [
    "new_country = countries = {'France':1,\n",
    " 'Germany':2,\n",
    " 'Brazil':3,\n",
    " 'Belgium':0,\n",
    " 'Switzerland':4,\n",
    " 'Venezuela':0,\n",
    " 'Austria':5,\n",
    " 'Mexico':0,\n",
    " 'USA':6,\n",
    " 'Sweden':7,\n",
    " 'Finland':0,\n",
    " 'Italy':8,\n",
    " 'Spain':9,\n",
    " 'UK':0,\n",
    " 'Ireland':10,\n",
    " 'Portugal':11,\n",
    " 'Canada':12,\n",
    " 'Denmark':0,\n",
    " 'Poland':0,\n",
    " 'Norway':0,\n",
    " 'Argentina':0}\n",
    "df_c['AbovecritGroups'] = df_c['ShipCountry'].map(new_country)\n",
    "df_c.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q5wkFHsLJJBh"
   },
   "outputs": [],
   "source": [
    "crit_country = {}\n",
    "for k,v in new_country.items():\n",
    "    if v != 0:\n",
    "        crit_country[k] = df_c.groupby('AbovecritGroups')['order_total'].get_group(v)\n",
    "    else:\n",
    "        crit_country['pop'] = df_c.groupby('AbovecritGroups')['order_total'].get_group(0)\n",
    "print(crit_country.keys())\n",
    "tukeys_countries = pd.DataFrame.from_dict(crit_country)\n",
    "tukeys_countries.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6AJTPVtKXMhk"
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd as tukey\n",
    "\n",
    "\n",
    "# create labels\n",
    "int_str = [str(x) for x in df_c['AbovecritGroups']]\n",
    "\n",
    "#Run Test\n",
    "tukey_results =tukey(df_c['order_total'], int_str, 0.05)\n",
    "\n",
    "#Put results in df\n",
    "dfH_tukey = pd.DataFrame(data=tukey_results._results_table.data[1:],\n",
    "                         columns=tukey_results._results_table.data[0])\n",
    "\n",
    "# checking for any signifigance\n",
    "dfH_tukey.loc[dfH_tukey['reject']==True]\n",
    "# dfH_tukey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qI0q7l3Xa_EP"
   },
   "outputs": [],
   "source": [
    "list2df(H4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NrxSNUclsYdQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "-qewqDkPectU",
    "ajT5x1OGna0r"
   ],
   "name": "Hypothesis Testing Outline.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
